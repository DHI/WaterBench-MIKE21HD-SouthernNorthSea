{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are several data points on the same day.\n",
    "# We assume that data is uniformly distributed across the day.\n",
    "# We will add a small time increment to each data point to make them unique.\n",
    "\n",
    "def add_time_stamps(df):\n",
    "    # Resample dates with duplicate indices by adding hours and minutes\n",
    "    # Find duplicate dates in index\n",
    "    duplicate_dates = df.index[df.index.duplicated(keep=False)]\n",
    "    \n",
    "    for date in set(duplicate_dates):\n",
    "        duplicates = df.loc[date]\n",
    "        # Calculate time increment based on the number of duplicates\n",
    "        num_duplicates = len(duplicates)\n",
    "        time_increment = datetime.timedelta(days=1) / num_duplicates\n",
    "\n",
    "        # Assign new unique timestamps to each duplicate\n",
    "        times = [date + i * time_increment for i in range(len(duplicates))]\n",
    "        df.loc[date, 'new_index'] = times\n",
    "    \n",
    "    # Set the new unique datetime index\n",
    "    df.set_index('new_index', inplace=True)\n",
    "    df.index.name = 'datetime'  # Rename the index for clarity\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_u_v(speed, direction):\n",
    "    # Convert direction from CW (North = 0°) to CCW (East = 0°)\n",
    "    direction_ccw_deg = (90 - direction) % 360\n",
    "    direction_rad = np.deg2rad(direction_ccw_deg)\n",
    "\n",
    "    # Calculate u- and v-components\n",
    "    u = speed * np.cos(direction_rad)\n",
    "    v = speed * np.sin(direction_rad)\n",
    "\n",
    "    return u,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_save_CMEMS_data(obs_dir,platform_name):\n",
    "\n",
    "    all_cur_list = []\n",
    "    longitudes = []\n",
    "    latitudes = []\n",
    "    for o in obs_dir:\n",
    "        ds = nc.Dataset(o)\n",
    "        formatted_time = []\n",
    "        start = datetime.date(1950,1,1)\n",
    "        for days in ds[\"TIME\"][:].data:\n",
    "            formatted_time.append(start + datetime.timedelta(days = days))\n",
    "\n",
    "        if \"EWCT\" in ds.variables.keys():\n",
    "            ew_cur = ds[\"EWCT\"][:].data\n",
    "            ew_cur[ds[\"EWCT\"][:].mask] = np.nan # Set fill values to nan\n",
    "            ew_cur_da = np.nanmean(ew_cur,axis=1) # depth averaged East-West current\n",
    "            ew_cur_da[(ew_cur_da>500) | (ew_cur_da<-500)] = np.nan # Set invalid values to nan\n",
    "\n",
    "            ns_cur = ds[\"NSCT\"][:].data\n",
    "            ns_cur[ds[\"NSCT\"][:].mask] = np.nan # Set fill values to nan\n",
    "            ns_cur_da = np.nanmean(ns_cur,axis=1) # depth averaged North-South current\n",
    "            ns_cur_da[(ns_cur_da>500) | (ns_cur_da<-500)] = np.nan # Set invalid values to nan\n",
    "        elif \"HCSP\" in ds.variables.keys():\n",
    "            cur_s = ds[\"HCSP\"][:].data\n",
    "            cur_d = ds[\"HCDT\"][:].data\n",
    "\n",
    "            cur_s[ds[\"HCSP\"][:].mask] = np.nan # Set fill values to nan\n",
    "            cur_d[ds[\"HCDT\"][:].mask] = np.nan # Set fill values to nan\n",
    "\n",
    "            u,v = convert_to_u_v(cur_s, cur_d)\n",
    "            \n",
    "            ew_cur_da = np.nanmean(u,axis=1) # depth averaged East-West current\n",
    "            ns_cur_da = np.nanmean(v,axis=1) # depth averaged North-South current\n",
    "            # ew_cur_da[(ew_cur_da>200) | (ew_cur_da<-200)] = np.nan # Set invalid values to nan\n",
    "\n",
    "\n",
    "        lon = np.nanmean(ds[\"LONGITUDE\"][:].data)\n",
    "        lat = np.nanmean(ds[\"LATITUDE\"][:].data)\n",
    "        longitudes.append(lon)\n",
    "        latitudes.append(lat) \n",
    "\n",
    "        cur = pd.DataFrame({\"u\": ew_cur_da,\"v\": ns_cur_da}, index = pd.DatetimeIndex(formatted_time))\n",
    "        try:\n",
    "            quality_filter = ((ds[\"HCSP_QC\"][:].data<=2).any(axis=1)) & ((ds[\"HCDT_QC\"][:].data<=2).any(axis=1))\n",
    "        except IndexError:\n",
    "            quality_filter = ((ds[\"EWCT_QC\"][:].data<=2).any(axis=1)) & ((ds[\"NSCT_QC\"][:].data<=2).any(axis=1))\n",
    "        cur = cur[quality_filter]\n",
    "        cur = cur[(cur.index >\"2021-12-31\") & (cur.index <\"2024-01-01\")]\n",
    "\n",
    "        #  Add timestamps\n",
    "        cur = add_time_stamps(cur)\n",
    "        \n",
    "        all_cur_list.append(cur)\n",
    "\n",
    "    all_cur=pd.concat(all_cur_list)\n",
    "    # Replace missing entries with nan such that we have a full date time index\n",
    "    freq=all_cur.index[1]-all_cur.index[0]\n",
    "    all_cur = all_cur.set_index(all_cur.index).resample(freq).sum().replace(0.00, np.nan) \n",
    "    all_cur = np.round(all_cur.dropna(),decimals=4)\n",
    "    all_cur.index.name = \"datetime_UTC\"\n",
    "    all_cur.to_csv(f\"../observations/{platform_name}_u_v.csv\")\n",
    "\n",
    "    \n",
    "    if Path(\"../observations/current_stations.csv\").exists():\n",
    "        locations_all = pd.read_csv(\"../observations/current_stations.csv\",index_col=0)\n",
    "        locations_all.loc[platform_name] = [np.round(np.mean(longitudes),decimals=6),np.round(np.mean(latitudes),decimals=6)]\n",
    "    else:\n",
    "        locations_all = pd.DataFrame({\"Longitude\": [np.round(np.mean(longitudes),decimals=6)],\n",
    "                              \"Latitude\": [np.round(np.mean(latitudes),decimals=6)]},index=[platform_name])\n",
    "    \n",
    "    locations_all.to_csv(\"../observations/current_stations.csv\")\n",
    "\n",
    "    return all_cur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of remaining platforms:\n",
    "- [] DB\n",
    "- [] MO\n",
    "- [] IJmondstroompaal2      GOOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS: DB is outside of model domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The modelskill package can be used to compare model results with observations.\n",
    "# For more info on modelskill, see https://github.com/DHI/modelskill\n",
    "# obs_fldr = \"raw_data/CMEMS/\"\n",
    "# # Collect observation directories in list\n",
    "# obs_dir = [f\"{obs_fldr}GL_TS_DB_6301615.nc\"]\n",
    "\n",
    "# ds = nc.Dataset(obs_dir[0])\n",
    "# ds.variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_and_save_CMEMS_data(obs_dir,\"DB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['TIME', 'TIME_QC', 'DEPH', 'LATITUDE', 'LONGITUDE', 'STATION', 'OSAT', 'OSAT_QC', 'OSAT_DM', 'TEMP', 'TEMP_QC', 'TEMP_DM', 'HCSP', 'HCSP_QC', 'HCDT', 'HCDT_QC', 'PSAL', 'PSAL_QC', 'PSAL_DM'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_fldr = \"raw_data/CMEMS/\"\n",
    "# Collect observation directories in list\n",
    "obs_dir = [f\"{obs_fldr}NO_TS_MO_6201065.nc\"]\n",
    "\n",
    "ds = nc.Dataset(obs_dir[0])\n",
    "ds.variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4.Variable'>\n",
       "float32 HCSP(TIME, DEPTH)\n",
       "    standard_name: sea_water_speed\n",
       "    units: m s-1\n",
       "    _FillValue: 9.96921e+36\n",
       "    long_name: Horizontal current speed\n",
       "    valid_min: 0.001\n",
       "    valid_max: 1.5\n",
       "    coordinates: TIME LATITUDE LONGITUDE DEPH STATION\n",
       "    ancillary_variables: HCSP_QC\n",
       "    data_mode: R\n",
       "unlimited dimensions: \n",
       "current shape = (1193772, 30)\n",
       "filling off"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"HCSP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4.Variable'>\n",
       "float32 HCDT(TIME, DEPTH)\n",
       "    standard_name: direction_of_sea_water_velocity\n",
       "    units: degree\n",
       "    _FillValue: 9.96921e+36\n",
       "    long_name: Current to direction relative true north\n",
       "    valid_min: 0.0\n",
       "    valid_max: 360.0\n",
       "    coordinates: TIME LATITUDE LONGITUDE DEPH STATION\n",
       "    ancillary_variables: HCDT_QC\n",
       "    data_mode: R\n",
       "unlimited dimensions: \n",
       "current shape = (1193772, 30)\n",
       "filling off"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"HCDT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4.Variable'>\n",
       "float64 TIME(TIME)\n",
       "    long_name: Time\n",
       "    standard_name: time\n",
       "    units: days since 1950-01-01T00:00:00Z\n",
       "    valid_min: -90000.0\n",
       "    valid_max: 90000.0\n",
       "    axis: T\n",
       "    ancillary_variables: TIME_QC\n",
       "    calendar: standard\n",
       "unlimited dimensions: \n",
       "current shape = (1193772,)\n",
       "filling off"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"TIME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frtp\\AppData\\Local\\Temp\\ipykernel_43080\\627281904.py:32: RuntimeWarning: Mean of empty slice\n",
      "  ew_cur_da = np.nanmean(u,axis=1) # depth averaged East-West current\n",
      "C:\\Users\\frtp\\AppData\\Local\\Temp\\ipykernel_43080\\627281904.py:33: RuntimeWarning: Mean of empty slice\n",
      "  ns_cur_da = np.nanmean(v,axis=1) # depth averaged North-South current\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime_UTC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00</th>\n",
       "      <td>-0.3121</td>\n",
       "      <td>0.0813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:12:00</th>\n",
       "      <td>-0.3254</td>\n",
       "      <td>0.1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:24:00</th>\n",
       "      <td>-0.3145</td>\n",
       "      <td>0.0920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:36:00</th>\n",
       "      <td>-0.3498</td>\n",
       "      <td>0.0860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:48:00</th>\n",
       "      <td>-0.3303</td>\n",
       "      <td>0.0713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:00:00</th>\n",
       "      <td>0.6634</td>\n",
       "      <td>0.1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:12:00</th>\n",
       "      <td>0.6220</td>\n",
       "      <td>0.1549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:24:00</th>\n",
       "      <td>0.5882</td>\n",
       "      <td>0.1134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:36:00</th>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:48:00</th>\n",
       "      <td>0.4964</td>\n",
       "      <td>0.1424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82548 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          u       v\n",
       "datetime_UTC                       \n",
       "2022-01-01 00:00:00 -0.3121  0.0813\n",
       "2022-01-01 00:12:00 -0.3254  0.1012\n",
       "2022-01-01 00:24:00 -0.3145  0.0920\n",
       "2022-01-01 00:36:00 -0.3498  0.0860\n",
       "2022-01-01 00:48:00 -0.3303  0.0713\n",
       "...                     ...     ...\n",
       "2023-12-31 23:00:00  0.6634  0.1102\n",
       "2023-12-31 23:12:00  0.6220  0.1549\n",
       "2023-12-31 23:24:00  0.5882  0.1134\n",
       "2023-12-31 23:36:00  0.5730  0.1488\n",
       "2023-12-31 23:48:00  0.4964  0.1424\n",
       "\n",
       "[82548 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_save_CMEMS_data(obs_dir,\"MO_NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IJmondstroompaal2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip this station, since it is too close to shore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_fldr = \"raw_data/CMEMS/\"\n",
    "# # Collect observation directories in list\n",
    "# obs_dir = [f\"{obs_fldr}NO_TS_MO_IJmondstroompaal2.nc\"]\n",
    "\n",
    "# ds = nc.Dataset(obs_dir[0])\n",
    "# ds.variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_and_save_CMEMS_data(obs_dir,\"IJmondstroompaal2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WBOresund",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
